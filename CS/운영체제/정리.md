# 운영체제란?
<details>
<summary>답변</summary>

* 사용자에게는 인터페이스를 제공하고 컴퓨터 시스템의 자원을 효율적으로 관리하는 소프트웨어 (내 답변)
* 일반적으로 하드웨어를 관리하고, 응용 프로그램과 하드웨어 사이에서 인터페이스 역할을 하며 시스템의 동작을 제어하는 시스템 소프트웨어  (검색 답변)
* 시스템의 자원과 동작을 관리하는 소프트웨어로 프로세스, 저장장치, 네트워킹, 사용자, 하드웨어를 관리함 (장고 답변)

  * 역할
  1. 프로세스 관리
  2. 저장장치 관리
  3. 네트워킹
  4. 사용자 관리
  5. 디바이스 드라이버

</details>

# Process와 Thread 차이점
<details>
<summary>답변</summary>

* 프로세스는 프로그램을 메모리 상에서 실행중인 작업단위를 말하고, 스레드는 프로세스 안에서 실행되는 여러 흐름 단위
* 프로세스는 메모리와 CPU를 프로세스마다 할당받아서 사용, 스레드는 프로세스 안에서 다른 스레드와 메모리와 CPU를 공유해서 사용

</details>

- 스레드와 프로세스 콘텍스트 스위치 차이 이유
  * 스레드는 프로세스의 자원을 공유하면서 사용되기 때문에 프로세스가 바뀌지 않는 이상 데이터가 남아있고 스레드 스위칭시 그대로 사용 가능하지만, 프로세스 스위칭하게 되면 캐시 정보, 가상 메모리, TLB등의 정보가 모두 지워지기 때문에 데이터 접근의 시간이 오래 걸림
  * 스레드 스위칭 중에는 가상 메모리 공간이 동일하게 남는 반면에 프로세스 스위칭시에는 그렇지 못하다.
  
- 프로세스 스케줄러에 대해
  * 멀티 프로세스 운영체제에서 프로세스의 CPU할당 순서 및 방법을 결정 짓는 것을 프로세스 스케쥴링이라고 함

# 멀티 프로세스와 멀티 스레드
<details>
<summary>답변</summary>

* 멀티 프로세스는 하나의 컴퓨터에 여러 CPU 장착해서 여러 프로세스들을 동시에 처리(병렬)
  * 안정성은 높지만, 각각 독립된 메모리 영역을 갖고 있어, 작업량이 많으면 오버헤드 발생, context switching(프로세스를 바꾸는 과정에서 상태 정보를 저장하고 복원하는 일련의 과정)으로 인한 성능 저하
* 멀티 스레드는 하나의 응용 프로그램에서 여러 스레드를 구성해서 각 스레드가 하나의 작업을 처리함, 공유 메모리를 통해 다수의 작업을 동시에 처리
  * 시간, 자원 손실이 감소, 전역 변수와 정적 변수 자료 공유 가능하나 안정성 문제가 있음

</details>


- 실행파일 생성 과정

# 프로그램 실행과정
<details>
<summary>답변</summary>

* 프로그램을 실행하면, 하드디스크에서 메모리로 저장이 되고, 연산을 위해 메모리에서 CUP로 Fetch됩니다.(메인 메모리 -> CUP내부로 옮기는 것)
* 명령어 수행을 위해서 Control Unit이 명령어에서 바이너리 코드로 Decode(해석)한 후, ALU에서 Execution(연산) 후 연산된 값을 레지스터에 저장
* 위 과정이 명령어 사이클, fetch -> decode -> 간접 주소일 경우 메모리로부터 유효 주소 읽어 옴 -> 명령어 실행
</details>


# 캐시란?
<details>

<summary>답변</summary>

* 메모리와 CPU 간의 속도 차이를 완화하기 위해서 메모리의 데이터를 미리 가져와 저장해두는 임시 장소를 말합니다.
* CPU가 미리 사용할 것으로 예상되는 데이터(재접근시)를 미리 가져다 놓음. (CPU내부에 존재, CPU내부 버스의 속도로 작동, 메모리와 CPU사이에 있는 경우도 있음)
* 사용할 데이터가 있을 캐시에 있을 경우는 캐시 히트, 없으면 캐시 미스라고 함
* 캐시 히트를 높이는 법 중 하나는 캐시 용량을 늘리기
* 캐시 라인은 캐시에 저장하는 데이터를 데이터의 메모리 주소를 함께 저장해서 빠르게 접근하는 것을 말합니다.
</details>


# 메모리구조
<details>
<summary>답변</summary>

* 메모리 구조에는 크게 네가지 종류가 존재, Code, Data, Heap, Stack
* Code는 소스코드가 들어가는 부분 / 코드 자체를 구성하는 메모리 영역(프로그램 명령)
* Data는 전역변수, 정적변수가 할당되는 부분 / 배열도
* Heap은 사용자가 직접 관리하는 영역으로 데이터가 동적으로 할당되는 공간
* Stack은 함수의 호출정보, 지역변수, 매개변수들이 저장됨

</details>

  - 전역변수와 정적변수의 차이
    * 전역 변수는 해당파일 뿐만 아니라, 다른 파일에서도 해당 변수에 접근이 가능한 변수
    * 정적 변수는 해당 변수가 선언된 scope에 따라 접근 가능한 범위가 결정됨
  - 가시성(visibility)과 경합조건
    * 멀티 스레드에서 가시성은 변수의 값은 CPU 메모리와 메인 메모리에 저장이 되는데, 이 변수 값을 가져올 때 어디에서 가져오는 지를 알 수 없는 문제말합니다. 이를 해결하기 위해 volatile을 사용해 메인 메모리에서만 변수를 가져오게 합니다.
    * 경합조건은 멀티스레드에서 한 객체를 공유하는 상황에서 이 객체에 멀티 스레드에서 동시에 작업이 수행됐을 때 예상과는 다른 값이 나오는 경우를 말합니다. synchronized를 사용해서 오직 한 시점에 하나의 블록만 객체에 접근할 수 있도록 해줍니다.
  - 유효주소, 주소지정방식
    * 유효주소란 주소 지정방식에 의해 결정되는 기억장치 주소 혹은 레지스터
    * 주소 지정방식은 연산에 필요한 기억장치 주소나 레지스터를 알아내는 데 사용하는 방식
  - 메모리 할당 알고리즘
    * 다양한 프로그램들이 메모리 적재와 종료를 반복하면서 불규칙한 메모리 빈공간이 생기는데, 이때 여러 빈 공간중 프로세스를 어느 곳에 할당해 줄지 정하는 알고리즘을 말합니다.
    * 종류 
      * 최초 적합(First-fit) - 메모리를 처음부터 검사해서 가장 첫번째로 사용 가능한 곳에 공간 할당
      * 최적 접합(Best-fit) - 메로리 공간들 중 프로세스가 들어갈 수 있는 가장 작은 공간 할당
      * 최악 접합(Worst-fit / Next-fit) - 프로세스를 메모리 공간 중 가장 큰 곳에 할당 

# CPU 스케줄러
<details>
<summary>답변</summary>

* 준비큐에 있는 프로세스에 대해서 CPU를 할당하는 방법으로 크게 다섯가지가 존재, FCFS, SJF, SRT, Priority Scheduling, Round Robin
* FCFS(First Come First Served) - 먼저 온 순서대로 처리, 비선점형 스케줄링
* SJF(Shortest Job First) - 다른 프로세스가 도착해도 CPU burst time이 짧은 프로세스에 선 할당, 빈선점형 스케줄링
* SRT(Shotest Remaining Time) - CPU할당 받을때 프로세스의 남은 작업시간이 가장 적은 프로세스를 선택
* Priority Scheduling - 우선순위가 가장 높은 프로세스에 CPU를 할당하는 스케줄링, 우선순위는 정수로 표현, 낮을 수록 높음, 선정형, 비선점형 둘다 존재
* Round Robin - 한 프로세스가 할당 받은 시간동안 작업 후 작업을 끝내지 못하면 작업 큐 뒤로 가서 작업차례를 기다리는 방식
</details>

  - 스레싱이란?
    * 잦은 입출력으로 페이지 부재가 많이 생겨 작업이 멈춘 것 같은 상태를 의미합니다.
  - IPC란?
    * 프로세스가 다른 프로세스와 데이터를 주고 받는 것을 말합니다. 프로세스 간 통신
    * 프로세스 내부 데이터 통신, 프로세스 간 데이터 통신, 네트워크를 이용한 데이터 통신이 있습니다.
  - Race Condition?
    * 프로세스가 공유 자원을 병행적으로 읽거나 쓰는 상황을 경쟁조건이 발생했다고 말합니다.
  - User, Kernel 스레드 차이
    * 스레드 지원 주체에 따라 Kernel level과 User level로 분류할 수 있습니다.
    * 커널 레벨 스레드는 OS에서 구현이 되고, 커널이 스레드 생성 및 스케쥴링 등을 관리 하지만 사용자 레벨에 비해 생성 및 관리가 느림
    * 스레드 기능을 제공하는 라이브러리를 활용하는 방식, 사용자 영역에서 스레드 연산 수행, 동일한 메모리 영역에서 스레드가 생성, 관리되므로 속도가 빠름

# 가상 메모리
<details>
<summary>답변</summary>

* 모든 프로세스에서 메모리를 할당하기에는 메모리의 크기가 한계가 있어서 프로세스에서 사용하는 부분만 메모리에 올리고, 나머지는 디스크에 보관하는 기법을 가상 메모리라고 함

</details>

  - 메모리 단편화
    * 메모리 공간이 작은 조각으로 나누어져서 사용가능한 공간은 충분하지만, 할당이 불가능한 상태를 말합니다.
  - 페이징기법
    * 프로세스의 크기에 상관없이 메모리를 같은 크기로 나누는 것을 의미합니다.
  - 세그먼테이션 기법
    * 프로세스 크기에 따라 메모리를 나누는 것을 의미합니다.
  - 메모리풀
    * 메모리의 일정공간을 미리 확보해두고 필요에 따라 확보한 메모리로부터 할당 및 반환하면서 그 공간을 채워주는 기법을 말합니다.
    * 메모리 단편화 문제 해결방법
  
  - MMU란?
    * Memory Management Unit은 CPU코어 내부에 탑재되어 가상 메모리 주소를 실제 메모리 주소로 변환해주는 장치를 말합니다.
  - TLB란?
    * Translation Look-aside Buffer는 가상 메모리 주소를 실제 메모리 주소로 변환하는 속도를 높이기 위해 사용되는 캐시입니다.
    * 가장 최근에 사용된 가상 메모리 주소와 물리 주소의 변환 테이블을 저장하기 때문에 일종의 주소 변환 캐시라고 할 수 있습니다.

# 페이지 부재시 절차

<details>
<summary>답변</summary>

* 프로세스가 페이지를 요청했을 때 그 페이지가 메모리에 없는 상황을 페이지 부재라고 합니다.
* 해결 과정
  1. 메모리 관리자는 스왑 영역에 있는 페이지를 메모리의 비어 있는 프레임으로 가져옴 (스왑인)
  2. 프레임에 페이지가 들어오면 페이지 테이블의 유효 비트는 (1 -> 0) 바뀌고 주소 필드 값도 바뀜 (해당 메모리 프레임 주소로) 페이지 테이블 갱신
  3. 해당 프레임으로 접근하여 해당 데이터를 프로세스에 넘김
* 페이지 부재가 발생하면 위 과정을 거쳐 스왑 영역에 있는 페이지를 메모리의 빈 영역에 올리고 페이지 테이블을 갱신합니다.
* 이때 메모리에 빈 프레임이 없으면 페이지 교체 알고리즘을 통해 프레임 중 하나를 스왑영역으로 보냅니다.

- 페이지 교체 알고리즘
    * 메모리를 관리하는 운영체제에서 필요한 페이지가 주기억장치에 적재되지 않을 시(페이지 부재) 어떤 페이지를 선택하여 교체할지 고르는 알고리즘을 말함
    * 페이지 갱신 시 물리 메모리가 비어있지 않으면 스왑영역(하드디스크)으로 보낼 페이지를 결정하는 알고리즘을 말합니다.
    * 앞으로 사용이 적을 걸로 예상되는 페이지를 대상 페이지로 설정하여 페이지 부재를 줄이고 성능을 향상 시킴
    * 종류
      * OPT (앞으로 가장 오랫동안 사용되지 않을 페이지 교체)
      * FIFO (First In First Out)
      * LRU (Least Recently Used), LFU (Least Frequently Used)
      * MFU (Most Frequently Used) (가정 가장 많이 사용된 페이지가 앞으로는 사용되지 않을 것이다.)
      * NUR (Not Used Recently)
</details>

# 인터럽트란?	
<details>
<summary>답변</summary>

* 주변 장치의 입출력 요구나 하드웨어의 이상 현상을 CPU에 알려주는 역할을 하는 신호

- System Call
  * 커널이 자기 자신을 보호하기 위해 만든 인터페이스
  * 커널은 사용자나 응용 프로그램으로부터 컴퓨터 자원을 보호하기 위해 자원에 직접 접근하는 것을 차단함
  * 자원을 이용하기 위해서는 시스템 호출이라는 인터페이스를 이용하여 접근해야 함
  * 커널이 데이터를 가져오거나 저장하는 것을 전적으로 책임지기 때문에 컴퓨터 자원을 관리하기 수월함
  * 시스템콜 유형
    * 프로세스 제어
    * 파일 관리
    * 디바이스 관리 
    * 정보 유지보수
    * 커뮤니케이션
  * 작업 과정
    1. 프로세스가 System Call 호출
    2. Trap()을 방생시켜 하던 작업을 멈추고 상태 저장 후 커널 모드로 진입
    3. 요청받은 작업 수행
    4. 작업 끝나면 User mode로 돌아와 하던 작업 이어서 진행

  - 프로세스 제어 명령
    * fork(), exit(), wait()
  - fork(), vfork() 차이
    * fork()는 새로운 프로세스를 생성하기 위해서 사용하는 시스템 콜, fork()를 호출한 프로세스를 부모 프로세스, 생성된 프로세스를 자식 프로세스 
    * 단점 - 부모 프로세스의 자원 복사하여 프로세스를 구성하기 때문에 자원을 복사하는데 시간이 오래 걸림
    * vfork()는 부모 프로세스와 자원을 공유함, 더 빠르게 프로세스를 생성 가능
    * 자원 공유 때문에 생길 수 있는 race condition을 방지하기 위해서 부모 프로세스는 자식 프로세스가 exit하거나 execve가 호출되기 전까지 블록됨

  - 시스템콜과 서브루틴 차이
    * 서브루틴은 동일한 처리를 프로그램내의 여러 곳에서 필요로 할 때 사용
    * CPU의 서브루틴 호출 명령에 의해 동작이 시작됨
</details>


# 동기, 비동기란?

<details>
<summary>답변</summary>

* 동기(Synchronous)는 현재 작업의 응답이 끝남과 동시에 다음 작업이 요청 됨
  * 함수 호출하는 곳에서 호출되는 함수가 결과를 반환할 때까지 기다림, 작업 완료 여부를 계속해서 확인
* 비동기(Asynchronous)는 현재 작업의 응답이 끝나지 않은 상태에서 다음 작업이 요청됨
  * 함수를 호출하는 곳에서 결과를 기다리지 않고, 다른 함수(callback)에서 결과를 처리
  * 작업 완료 여부를 확인하지 않는다.

- 블록킹, 논블록킹
  * 블록킹 (Blocking)
    * 블록킹은 제어권이 호출된 함수에게 넘어가서 호출된 함수 내에서 작업이 모두 끝난 후 호출한 함수에게 다시 제어권이 넘어옴
    * 작업이 완료된 후 새로운 작업을 수행할 수 있음
  * 논블록킹 (Non-Blocking)
    * 제어권이 계속 호출한 함수에 있기 때문에 작업의 완료여부와 관계없이 새로운 작업을 수행할 수 있음

* 동기 === 블록킹, 비동기 === 논블록킹의 개념으로 생각할 수 있다. 유사하게 동작하지만, 주요 관심사에 따라 차이가 난다. 4가지 조합으로 사용할 수 있음

- 동기 IO 처리과정 : 프로세스 A가 디스크에서 어떤 데이터 읽어올때 상황
</details>


- 입출력 처리방식
  - DMA (Direct Memory Access)
    * CPU의 개입 없이 주변장치와 주기억장치와의 데이터 전송이 이루어지는 방식
    * CPU의 프로세스 처리속도보다 I/O 장치의 입출력 속도가 느리기때문에 CPU가 직접 I/O처리하면 처리속도 차 때문에 CPU의 작업 대기시간 늘어남
    * DMA방식을 사용하면, CPU가 I/O 작업을 따로 하지 않게 됨, CPU는 상태정보와 제어정보만을 교환하면 되서 효울적
  - Cycle Stealing
  
# 데드락
<details>
<summary>답변</summary>

* 데드락은 프로세스가 자원을 얻지 못해서 다음 작업을 못하는 상태
* 상호배제, 점유대기, 비선점, 순환대기 네가지 조건이 동시에 발생해야 성립가능
* 데드락 해결 방법에는 데드락 상태 예방, 상태 회피, 상태 검출, 상태 회복이 있습니다.
* 회피 기법은 프로세스가 자원 할당시 어느 수준 이상의 자원을 나누어주면 교착상태가 발생하는지 파악하여 그 수준 이하로 자원을 나눠주는 방법을 말합니다.
  - 해결경험?
</details>


# PCB(Process Control Block) 이란?
<details>
<summary>답변</summary>

* 프로세스 제어 블록(PCB)은 프로세스를 실행하는 데 필요한 중요한 정보를 보관하는 자료구조를 말합니다.
* 모든 프로세스는 프로세스 제어 블록을 가지고 있고, 프로세스 생성 시 만들어져서 프로세스가 실행을 완료하면 폐기됨
* PCB 구성 요소 - 포인터, 프로세스 상태, 프로세스 구분자, 프로그램 카운터, 프로세스 우선순위, 각종 레지스터 정보, 메모리 관리 정보, 할당된 자원 정보, 계정 정보, 부모 프로세스 구분자와 자식 프로세스 구분자
</details>

# Critical Section?	
<details>
<summary>답변</summary>

* 공유 자원 접근 순서에 따라 실행 결과가 달라지는 프로그램의 영역을 말합니다.
* 임계구역에서는 프로세스들이 동시에 작업을 하면 안됨
* 어떤 프로세스가 임계구역에 들어가면 다른 프로세스는 임계구역 밖에서 기다려야 하며 임계구역의 프로세스가 나와야 들어갈 수 있음
* 베타적으로 데이터를 갱신이나 사용하고 싶을 때 락킹하여서 지금 사용중인 데이터를 그 누구도 못건드리게 하고 싶을 때 locking을 사용하는데 이때 접근 불가한 영역을 critical Section
</details>

# Spin Lock 이란?
<details>
<summary>답변</summary>

* 만약 다른 스레드가 lock을 소유하고 있다면 그 lock이 반환될 때까지 계속 확인하며 기다리는 것을 말합니다.
* 자원 획득을 위해서 Sleep하지 않고 Lock이 반환될 때까지 계속 확인하며 기다림
* 장점 - 스핀락을 잘 사용하면 Context Switching을 줄여 효율을 높일 수 있음
  * 아주 작은 작업에서는 context switching할 필요가 없어서 세마포어나 뮤텍스보다 더 효율적이다.
* 단점 - busy waiting은 무한루프를 돌면서 다른 쓰레드에게 CPU를 양보하지 않기 때문에 Lock이 오래 유지되면 기다리면서 CPU 시간을 많이 소모함
</details>

- 동기화 종류

# Semaphore란?
<details>
<summary>답변</summary>

* 세마포어란 공유 자원에 여러 프로세스가 접근하는 것을 막는 것을 말합니다.
* 이를 위해서 현재 공유 자원이 상태를 나타내는 카운터 변수를 사용함, 변수는 운영체제 혹은 커널에 값으로 저장되며, 각 프로세스가 이를 확인할 수 있고, 값을 변경할 수 잇음
* 각 프로세스들은 이런 상태값을 확인하여 자원을 즉시 사용가능하면 사용하고,다른 프로세스가 자원을 사용중이라면 그것을 인지하고 일정 시간 기다렸다가 사용함
</details>

# Mutex란?
<details>
<summary>답변</summary>

* Critical Section을 가지는 쓰레드들의 Running time이 서로 겹치지 않도록 해주는 기법
* 뮤텍스는 Lock과 Unlock개념을 사용해서, 자원을 점유하고 있는 대상이 Lock권한을 가져서, 자원을 점유하기 시작하면 Lock을 걸게 됩니다. 
* 다른 대상들은 Unlock상태가 될 때까지 기다렸다가 나중에 해당 공유 자원에 접근할 수 있습니다.
</details>

# Mutex, Semaphore 차이
<details>
<summary>답변</summary>

* 뮤텍스는 세마포어의 일종입니다.
* 뮤텍스는 오직 1개의 프로세스 혹은 스레드만이 공유 자원에 접근할 수 있고, 세마포어는 지정된 변수의 값만큼 접근할 수 있습니다.
* 세마포어는 운영체제 혹은 커널 단위에서 해당 리소스 변수가 관리되어 현재 공유 자원을 사용 중인 대상 뿐만 아니라 다른 프로세스 및 스레드도 잠금 상태를 해제할 수 있다.
* 뮤텍스는 프로세스 단에서 관리되고 해당 변수를 가지고 있기 때문에 Lock을 가지고 있는 변수만이 Unlock을 할 수 있음
</details>

# Monitor란?
<details>
<summary>답변</summary>

* 세마포어 이후 프로세스 동기화 도구, 세마포어보다 고수준의 개념
* 구조
  * 공유자원 + 공유자원 접근 함수
  * 2개의 큐를 가지고 있음
  * 공유자원 접근함수에는 최대 1개의 스레드만 진입가능
* 모니터에는 공유자원에 접근할 수 있는 키의 획득과 해제를 모두 처리해서 간단함
* 공유 자원을 내부적으로 숨기고 공유 자원에 접근하기 위한 인터페이스만 제공함으로써 자원을 보호하고 프로세스 간에 동기화를 시킴 (시스템호출과 같은 개념)
</details>

# Thread-safe 란?
<details>
<summary>답변</summary>

* 멀티 스레드 프로그래밍에서 일반적으로 어떤 함수나 변수, 혹은 객체가 여러 스레드로부터 동시에 접근이 이루어져도 프로그램의 실행에 문제가 없음을 뜻함, 의도한 대로 동작
* 즉, 하나의 함수가 한 스레드로부터 호출되어 실행중일 때, 다른 스레드가 그 함수를 호출하여 동시에 함께 실행되더라도 각 스레드에서의 함수의 수행 결과가 올바로 나옴 

- Reentrant란?
* 재진입성으로, 어떤 함수가 Reentrant하다는 것은 여러 스레드가 동시에 접근해도 언제나 같은 실행 결과를 보장한다는 의미
* 만족하기 위해서는 서브루틴에서는 공유자원을 사용하지 않으면 된다.
</details>


# 인터럽트, 폴링 개념 및 차이
<details>
<summary>답변</summary>

* CPU의 작업과 저장장치의 데이터 이동을 입출력 관리자가 독립적으로 운영함으로써 시스템의 효율을 높히는 데, 이때 입출력 관리자가 CPU에 보내는 작업완료 신호
* 프로그램 실행 중 예기치 않은 상황이 발생할 경우 현재 실행 중인 작업을 즉시 중단하고, 발생된 상황에 대한 우선 처리가 필요함을 CPU에게 알리는 것
* 외/내부 입력장치는 CPU 하드웨어의 신호에 의해 발생, 소프트웨어 인터럽트는 명령어의 수행에 의해 발생
* 폴링 방식은 사용자가 명령어를 사용해 입력 핀의 값을 계속 읽어 변화를 알아내는 방식
* 인터럽트 방식은 MCU 자체가 하드웨어적으로 변화를 체크하여 변화 시에만 일정한 동작을 하는 방식
* 인터럽트 방식은 하드웨어로 지원을 받아야하는 제약이 있지만, 폴링에 비해 신속하게 대응 가능, 실시간 대응이 필요할 때 필수 기능
* 인터럽트는 발생시기를 예측하기 힘든 경우에 컨트롤러가 가장 빠르게 대응할 수 있는 방법
</details>

# Fault Tolerance 란?
<details>
<summary>답변</summary>

* 장애 허용 시스템이란 하드웨어나 소프트웨어의 결함, 오작동, 오류 등이 발생하더라도 규정된 기능을 지속적으로 수행할 수 있는 시스템을 말합니다.
* 작동 절차
  * 결함 감지
  * 결함 진단
  * 결함 통제 및 복구
</details>

(- gyoogle Tech Interview, 개발자 장고 참조)

<details>
<summary>답변</summary>


</details>